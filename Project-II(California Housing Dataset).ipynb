{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching data\n",
    "from sklearn import datasets\n",
    "cal_housing=datasets.fetch_california_housing()\n",
    "cal_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate input and output data\n",
    "df_x=pd.DataFrame(cal_housing.data,columns=cal_housing.feature_names)\n",
    "y=pd.DataFrame(cal_housing.target,columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying input dataset\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Null values\n",
    "print(df_x.isnull().sum())\n",
    "print(y.isnull().sum())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatypes of each column\n",
    "df_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no null values present based on below output\n",
    "#Concatenate the dataframes\n",
    "df_cal=pd.concat([df_x,y],axis=1)\n",
    "df_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for correlation \n",
    "df_cal.corr()\n",
    "\n",
    "#Here we observe that target variable has a good correaltion with MedInc variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe the dataset\n",
    "\n",
    "df_cal.describe()\n",
    "\n",
    "#From output it is observed in population column there are some outliers as we saw a significant difference between mean and median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers\n",
    "from scipy.stats import zscore\n",
    "print(\"with outliers:{}\".format(df_cal.shape))\n",
    "z_scores=zscore(df_cal)\n",
    "df_cal2=df_cal.loc[(abs(z_scores)<3).all(axis=1)]\n",
    "print(\"without outliers:{}\".format(df_cal2.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the dataset into input and output variable\n",
    "df_x=df_cal2.drop(columns=[\"target\", \"Latitude\", \"Longitude\", \"MedInc\"])\n",
    "y=df_cal2[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check for skewness\n",
    "df_x.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat the skewness\n",
    "for index in df_x.skew().index:\n",
    "    if df_x.skew().loc[index]>0.5:\n",
    "        df_x[index]=np.log(df_x[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again check the skewness\n",
    "df_x.skew()\n",
    "# The skew drop from 5.7 to 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Standard Scaler to bring all features to common scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(df_x)\n",
    "x=sc.transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred, color = \"yellow\")\n",
    "plt.plot(range(0,5),range(5))\n",
    "plt.xlabel(\"Y_test\")\n",
    "plt.ylabel(\"Y_preict\")\n",
    "plt.title(\"Y_test vs Y_predict\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hold Out Validation \n",
    "from sklearn.metrics import r2_score\n",
    "from timeit import default_timer as timer\n",
    "start_val = timer()\n",
    "print(\"r2_score is: {}\".format(r2_score(y_test,y_pred)))\n",
    "end_val = timer()\n",
    "print(\"Time taken for hold out validation :{}\".format(end_val-start_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cross validatiion \n",
    "from sklearn.model_selection import cross_val_score\n",
    "start_cross_val = timer()\n",
    "c_scores=cross_val_score(LinearRegression(),x,y,cv=5,scoring=\"r2\")\n",
    "print(\"mean r2 score: {}\".format(c_scores.mean()))\n",
    "print(\"std dev in r2 score: {}\".format(c_scores.std()))\n",
    "end_cross_val = timer()\n",
    "print(\"scores :{}\".format(c_scores))\n",
    "print(\"Time taken for cross validation :{}\".format(end_cross_val-start_cross_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOOCV: Leave one out cross validation \n",
    "#Here partitions are equal to number of instances in dataset\n",
    "start_loocv_val = timer()\n",
    "c_scores=cross_val_score(LinearRegression(),x,y,cv=5,scoring='neg_mean_squared_error')\n",
    "print(\"mean r2 score: {}\".format(c_scores.mean()))\n",
    "print(\"std dev in r2 score: {}\".format(c_scores.std()))\n",
    "end_loocv_val = timer()\n",
    "print(\"Time taken for LOO cross validation :{}\".format(end_loocv_val-start_loocv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
